{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "214fe53c-c1b5-4c34-8d21-9dee66e0a701",
   "metadata": {
    "id": "214fe53c-c1b5-4c34-8d21-9dee66e0a701"
   },
   "source": [
    "## Package Requirements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fba7b79-7b7a-4806-bada-717d7978d0e1",
   "metadata": {
    "id": "8fba7b79-7b7a-4806-bada-717d7978d0e1"
   },
   "outputs": [],
   "source": [
    "!pip3 install opencv-contrib-python numpy scikit-image"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29d4f893-20fe-482f-970e-bb4cb5fedb6c",
   "metadata": {
    "id": "29d4f893-20fe-482f-970e-bb4cb5fedb6c"
   },
   "source": [
    "### Import Software Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "069bfc3d-9bc1-40c1-8235-672049fcf7bf",
   "metadata": {
    "id": "069bfc3d-9bc1-40c1-8235-672049fcf7bf"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import cv2\n",
    "import pyvirtualcam\n",
    "from skimage import data, filters\n",
    "from collections import defaultdict\n",
    "import serial\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a76aa0cb-28f6-475f-b10e-1116899cb80e",
   "metadata": {
    "id": "a76aa0cb-28f6-475f-b10e-1116899cb80e"
   },
   "source": [
    "### Implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90dea86e-18ab-4e2d-b930-96701d03b5fc",
   "metadata": {
    "id": "90dea86e-18ab-4e2d-b930-96701d03b5fc"
   },
   "outputs": [],
   "source": [
    "from ultralytics import YOLO\n",
    "\n",
    "# Load a model\n",
    "model = YOLO(\"yolov8n.pt\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ad14bbe-c752-4f89-8692-58b9002e030b",
   "metadata": {
    "id": "2ad14bbe-c752-4f89-8692-58b9002e030b"
   },
   "outputs": [],
   "source": [
    "# Switch on LED\n",
    "\n",
    "def alertLED(com):\n",
    "    SerialObj = serial.Serial(com)\n",
    "\n",
    "    SerialObj.baudrate = 9600\n",
    "    SerialObj.bytesize = 8\n",
    "    SerialObj.parity = 'N'\n",
    "    SerialObj.stopbits = 1\n",
    "    time.sleep(3)\n",
    "    SerialObj.write(b'A')\n",
    "    SerialObj.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8ea96a3-8c54-4c85-b003-abb9689386a0",
   "metadata": {
    "id": "c8ea96a3-8c54-4c85-b003-abb9689386a0"
   },
   "outputs": [],
   "source": [
    "# Frame differencing\n",
    "\n",
    "def frameDiff(frame):\n",
    "    if frame is None:\n",
    "        sys.exit()\n",
    "\n",
    "    fgMask = backSub.apply(frame)\n",
    "\n",
    "\n",
    "    cv2.rectangle(frame, (10, 2), (100,20), (255,255,255), -1)\n",
    "    cv2.putText(frame, str(cap.get(cv2.CAP_PROP_POS_FRAMES)), (15, 15), cv2.FONT_HERSHEY_SIMPLEX, 0.5 , (0,0,0))\n",
    "\n",
    "    return fgMask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1dacbb3-9489-46e7-891a-32e8db0eaf62",
   "metadata": {
    "id": "e1dacbb3-9489-46e7-891a-32e8db0eaf62"
   },
   "outputs": [],
   "source": [
    "# Edge detection\n",
    "\n",
    "def frameCanny(frame, cmf):\n",
    "    # Convert current frame to grayscale\n",
    "    frame = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    # Calculate absolute difference of current frame and the median frame\n",
    "    dframe = cv2.absdiff(frame, cmf)\n",
    "\n",
    "    # thresholding to convert the frame to binary\n",
    "    ret, thres = cv2.threshold(dframe, 50, 255, cv2.THRESH_BINARY)\n",
    "\n",
    "    # dilate the frame a bit to get some more white area makes the detection of contours a bit easier\n",
    "    dilate_frame = cv2.dilate(thres, None, iterations=2)\n",
    "\n",
    "    canny = cv2.Canny(dilate_frame, 30, 200)\n",
    "\n",
    "    return dilate_frame, canny"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2efdc76c-b407-418b-96e0-892638d04986",
   "metadata": {
    "id": "2efdc76c-b407-418b-96e0-892638d04986"
   },
   "outputs": [],
   "source": [
    "def box_label(image, box, label='', color=(128, 128, 128), txt_color=(255, 255, 255)):\n",
    "    lw = max(round(sum(image.shape) / 2 * 0.003), 2)\n",
    "    p1, p2 = (int(box[0]), int(box[1])), (int(box[2]), int(box[3]))\n",
    "    cv2.rectangle(image, p1, p2, color, thickness=lw, lineType=cv2.LINE_AA)\n",
    "    if label:\n",
    "        tf = max(lw - 1, 1)  # font thickness\n",
    "        w, h = cv2.getTextSize(label, 0, fontScale=lw / 3, thickness=tf)[0]  # text width, height\n",
    "        outside = p1[1] - h >= 3\n",
    "        p2 = p1[0] + w, p1[1] - h - 3 if outside else p1[1] + h + 3\n",
    "        cv2.rectangle(image, p1, p2, color, -1, cv2.LINE_AA)  # filled\n",
    "        cv2.putText(image,\n",
    "                    label, (p1[0], p1[1] - 2 if outside else p1[1] + h + 2),\n",
    "                    0,\n",
    "                    lw / 3,\n",
    "                    txt_color,\n",
    "                    thickness=tf,\n",
    "                    lineType=cv2.LINE_AA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd90c3f1-9271-4e28-a56a-cd4e43ea7dfd",
   "metadata": {
    "id": "dd90c3f1-9271-4e28-a56a-cd4e43ea7dfd"
   },
   "outputs": [],
   "source": [
    "def plot_bboxes(image, boxes, labels=[], colors=[], score=True, conf=None):\n",
    "    #Define COCO Labels\n",
    "    if labels == []:\n",
    "        labels = {0: u'__background__', 1: u'person', 2: u'bicycle',3: u'car', 4: u'motorcycle', 5: u'airplane', 6: u'bus', 7: u'train', 8: u'truck', 9: u'boat', 10: u'traffic light', 11: u'fire hydrant', 12: u'stop sign', 13: u'parking meter', 14: u'bench', 15: u'bird', 16: u'cat', 17: u'dog', 18: u'horse', 19: u'sheep', 20: u'cow', 21: u'elephant', 22: u'bear', 23: u'zebra', 24: u'giraffe', 25: u'backpack', 26: u'umbrella', 27: u'handbag', 28: u'tie', 29: u'suitcase', 30: u'frisbee', 31: u'skis', 32: u'snowboard', 33: u'sports ball', 34: u'kite', 35: u'baseball bat', 36: u'baseball glove', 37: u'skateboard', 38: u'surfboard', 39: u'tennis racket', 40: u'bottle', 41: u'wine glass', 42: u'cup', 43: u'fork', 44: u'knife', 45: u'spoon', 46: u'bowl', 47: u'banana', 48: u'apple', 49: u'sandwich', 50: u'orange', 51: u'broccoli', 52: u'carrot', 53: u'hot dog', 54: u'pizza', 55: u'donut', 56: u'cake', 57: u'chair', 58: u'couch', 59: u'potted plant', 60: u'bed', 61: u'dining table', 62: u'toilet', 63: u'tv', 64: u'laptop', 65: u'mouse', 66: u'remote', 67: u'keyboard', 68: u'cell phone', 69: u'microwave', 70: u'oven', 71: u'toaster', 72: u'sink', 73: u'refrigerator', 74: u'book', 75: u'clock', 76: u'vase', 77: u'scissors', 78: u'teddy bear', 79: u'hair drier', 80: u'toothbrush'}\n",
    "    #Define colors\n",
    "    if colors == []:\n",
    "    #colors = [(6, 112, 83), (253, 246, 160), (40, 132, 70), (205, 97, 162), (149, 196, 30), (106, 19, 161), (127, 175, 225), (115, 133, 176), (83, 156, 8), (182, 29, 77), (180, 11, 251), (31, 12, 123), (23, 6, 115), (167, 34, 31), (176, 216, 69), (110, 229, 222), (72, 183, 159), (90, 168, 209), (195, 4, 209), (135, 236, 21), (62, 209, 199), (87, 1, 70), (75, 40, 168), (121, 90, 126), (11, 86, 86), (40, 218, 53), (234, 76, 20), (129, 174, 192), (13, 18, 254), (45, 183, 149), (77, 234, 120), (182, 83, 207), (172, 138, 252), (201, 7, 159), (147, 240, 17), (134, 19, 233), (202, 61, 206), (177, 253, 26), (10, 139, 17), (130, 148, 106), (174, 197, 128), (106, 59, 168), (124, 180, 83), (78, 169, 4), (26, 79, 176), (185, 149, 150), (165, 253, 206), (220, 87, 0), (72, 22, 226), (64, 174, 4), (245, 131, 96), (35, 217, 142), (89, 86, 32), (80, 56, 196), (222, 136, 159), (145, 6, 219), (143, 132, 162), (175, 97, 221), (72, 3, 79), (196, 184, 237), (18, 210, 116), (8, 185, 81), (99, 181, 254), (9, 127, 123), (140, 94, 215), (39, 229, 121), (230, 51, 96), (84, 225, 33), (218, 202, 139), (129, 223, 182), (167, 46, 157), (15, 252, 5), (128, 103, 203), (197, 223, 199), (19, 238, 181), (64, 142, 167), (12, 203, 242), (69, 21, 41), (177, 184, 2), (35, 97, 56), (241, 22, 161)]\n",
    "       colors = [(89, 161, 197),(67, 161, 255),(19, 222, 24),(186, 55, 2),(167, 146, 11),(190, 76, 98),(130, 172, 179),(115, 209, 128),(204, 79, 135),(136, 126, 185),(209, 213, 45),(44, 52, 10),(101, 158, 121),(179, 124, 12),(25, 33, 189),(45, 115, 11),(73, 197, 184),(62, 225, 221),(32, 46, 52),(20, 165, 16),(54, 15, 57),(12, 150, 9),(10, 46, 99),(94, 89, 46),(48, 37, 106),(42, 10, 96),(7, 164, 128),(98, 213, 120),(40, 5, 219),(54, 25, 150),(251, 74, 172),(0, 236, 196),(21, 104, 190),(226, 74, 232),(120, 67, 25),(191, 106, 197),(8, 15, 134),(21, 2, 1),(142, 63, 109),(133, 148, 146),(187, 77, 253),(155, 22, 122),(218, 130, 77),(164, 102, 79),(43, 152, 125),(185, 124, 151),(95, 159, 238),(128, 89, 85),(228, 6, 60),(6, 41, 210),(11, 1, 133),(30, 96, 58),(230, 136, 109),(126, 45, 174),(164, 63, 165),(32, 111, 29),(232, 40, 70),(55, 31, 198),(148, 211, 129),(10, 186, 211),(181, 201, 94),(55, 35, 92),(129, 140, 233),(70, 250, 116),(61, 209, 152),(216, 21, 138),(100, 0, 176),(3, 42, 70),(151, 13, 44),(216, 102, 88),(125, 216, 93),(171, 236, 47),(253, 127, 103),(205, 137, 244),(193, 137, 224),(36, 152, 214),(17, 50, 238),(154, 165, 67),(114, 129, 60),(119, 24, 48),(73, 8, 110)]\n",
    "\n",
    "    #plot each boxes\n",
    "    for box in boxes:\n",
    "    #add score in label if score=True\n",
    "        if score :\n",
    "            label = labels[int(box[-1])+1] + \" \" + str(round(100 * float(box[-2]),1)) + \"%\"\n",
    "        else :\n",
    "            label = labels[int(box[-1])+1]\n",
    "        #filter every box under conf threshold if conf threshold setted\n",
    "        if conf :\n",
    "            if box[-2] > conf:\n",
    "                color = colors[int(box[-1])]\n",
    "                box_label(image, box, label, color)\n",
    "        else:\n",
    "              color = colors[int(box[-1])]\n",
    "              box_label(image, box, label, color)\n",
    "\n",
    "    #show image\n",
    "    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "    cv2.imshow(\"YOLOv8\", image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb1054fd-d4fb-46c9-a96a-47b92aece4fb",
   "metadata": {
    "id": "cb1054fd-d4fb-46c9-a96a-47b92aece4fb",
    "outputId": "81986fe2-1904-4e55-c84c-8d4e9f42a37c"
   },
   "outputs": [],
   "source": [
    "#Background Estimatiion time\n",
    "backSub = cv2.createBackgroundSubtractorMOG2()\n",
    "\n",
    "# Open Video\n",
    "\n",
    "print(\"Video Camera: Initiating\" )\n",
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "ret = True\n",
    "while ret:\n",
    "    ret, frame = cap.read()\n",
    "    cv2.imshow('Frame', frame)\n",
    "\n",
    "    # Frame Differencing\n",
    "    fgMask = frameDiff(frame)\n",
    "    cv2.imshow('FG Mask', fgMask)\n",
    "\n",
    "    # Edget Detection\n",
    "    dilate_frame, canny = frameCanny(frame, fgMask)\n",
    "    cv2.imshow(\"frame differencing: Frame differencing\", dilate_frame)\n",
    "    cv2.imshow(\"frame differencing: Edge detection\", canny)\n",
    "\n",
    "    # YOLOv8 objection classification\n",
    "    results = model.predict(frame)\n",
    "    plot_bboxes(frame, results[0].boxes.boxes, conf=0.8)\n",
    "\n",
    "    # Exit\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "# Release video object\n",
    "cap.release()\n",
    "\n",
    "# Destroy all windows\n",
    "cv2.destroyAllWindows()"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
